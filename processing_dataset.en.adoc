[[processing]]
== Processing a dataset

If you have prepared a dataset in one of the suggested templates/formats, and used THE_TOOL before or used the two quick start guides, you should be able to upload and process a dataset by following the steps below.

For specific usage or error messages refer to the detailed user guide below.

=== Log in

. Go to the website of https://edna-tool.gbif-uat.org/[THE_TOOL^].
. Log in.
. Press *New Dataset* in the upper part of the page.

=== Upload data (step 1)

. Drag your dataset to the upload area, or click and select the file.
. Give the dataset a nickname (e.g. "my_first_dataset")
. Press *Start Upload*.
+
A green icon will indicate if a recogniced format is detected and looks OK according to some very basic data checks.

image::img/advanced_example_upload_warning.png[]

. (_optional_) Inspect your data in the data viewer by clicking on the eye icon next to the uploaded dataset
+ 
. Press *Proceed*

=== Map terms (step 2)

On this page you tell THE_TOOL which standardised field names (Darwin Core terms) correspond to which fields in your data.

TIP: Press *how to use this form* to get a guided tour of this page.

TIP: Press *Save mapping* once in a while to make sure that you will not be logged out and lose your work.

*First inspection*

. Inspect the overall structure and information on the page.
.. The upper section named *Sample* maps your sample data fields to Darwin Core terms (first column), automatically identifying and mapping fields from the *Samples* sheet (second column) and global fields from the *Study* sheet (third column) with their identically named Darwin Core counterparts.
.. The second section named *Taxon* does the same for taxonomic and sequence related information, auto-mapping fields from the Taxon sheet to identically named Darwin Core fields.
... If you uploaded sequences in a separate fasta file *Seqs.fasta*, this will be indicated in the mapping of term:dwc[DNA_sequences].
.. The last section *Unmapped fields* lists all the fields in your data, that has names which the tool did not automatically  recognize. Below there is an option to put unmapped fields into *Extended Measurement Or Facts*.

*Completing the mapping*

Starting from the top with *Sample* and *Taxonomy* information

. make sure that the automatically mapped fields are correct – both fields from the *Samples* table and from the *Study* table.
. take a look a the *Unmapped fields* and check if there are any fields in the uploaded data that have not been mapped.
.. For each unmapped field where you expect (or know) that there is a suitable Darwin Core term in either the *Sample* or *Taxonomy* section:
... Click on *Add mapping for another sample field* and inspect and search the list of available terms.
... Add the term, and select the field from the uploaded data that you wish to map.
... If you cannot find a relevant term, you may want to look at the official reoources with available terms XXX

If you still have *Unmapped fields*, that you wish to include in the dataset to be published to GBIF, you may consider acomodating those in *Extended Measurement Or Facts* (eMoF):

. Click on the "unmapped" field you wish to put into eMoF from the row of unmapped fields to transfer it to the the eMoF section below as a new entry.
. Add a measurement unit and other relevant information to the field, if possible.

Now, the mapping is complete.

NOTE: All available standard fields (from Occurrence Core, and the dna-derived extension) can be included in the upload files, and if spelled correctly no manual mapping is needed.

. Press *Proceed*.

=== Process data (step 3)

. Press *Process data*.
+
The tool goes through a series of steps which will be indicated as succesful with a green tick-mark, and finally produces standardized BIOM files, which the tool uses as an intermediate file format.
+
NOTE: If the barcoding region used for your dataset is one of the regions included in the https://www.gbif.org/tools/sequence-id[GBIF Sequence ID tool^], the option *assign taxonomy* will be available. You can use that to assign taxonomy to the OTUs by comparing the sequences with a reference database. NB: This overwrites any taxonomy provided in the data.

. Check that number of samples and taxa are as expected.
. Press *Proceed*

=== Review (step 4)

Here the data can be explored to check that everything is OK. The options in this step are intended as sanity checks of the data to ensure that e.g. negative control samples have been removed, and that the mapping is as expected.

* Check the map and verify that the samples are placed geographically where expected.
* Check the taxonomic barchart to ensure that taxonomic composition is as expected.
* Check ordination plots (PCoA/MDS) – that visualise compositional differnence of the samples – for outliers (any control samples that should have been excluded?).
* Select single samples from the map or from charts and explore their metadata and taxonomy in the panel to the right.
. Press *Proceed*

=== Add metadata (step 5)

On this page, dataset metadata (dataset description, persons and affiliations, etc.) is added in a minimalistic form.

TIP: toggle "Show help" to get guidance text for the fields.

. Add a meaningful title (Cecilie XXX).
. Select a licence.
. Give as rich a dataset description as you can.
. Add contact information for all persons you wish to associate with the dataset.
. Be sure to put the person that knows about this dataset (you?) as the contact, so that response and issues about this dataset is directed to the correct person.
. Fill out the other fields as good as possible.
. Press *Proceed*.

=== Export (step 6)

This last page of the process produces a Darwin Core Archive that can be published directly to the https://www.gbif-uat.org/[GBIF test environment (UAT)^] from THE_TOOL. This archive can also be published properly to GBIF.org eventually.

. Press *Create DWC archive*.
+
This creates the Darwin Core Archive from the data, going through a series of steps, that will be indicated as succesful with a green tick-mark.
. Press *Publish to GBIF test environment (UAT)*.
+
A prompt will inform that it takes some minutes before the data is fully ingested and will show up with all samples in the GBIF test environment (and the map will only appear the next day). A link to the dataset in the test environment will appear next to the *Publish* button.

. Explore the dataset in the test environment
. Ensure that all information and data is processed and displayed appropriately.

WARNING: Currently, THE_TOOL is in the GBIF test environment, and it is still being developed and has not been formally released. Uploaded datasets and the produced BIOM files and Darwin Core archives should be downloaded and stored locally to ensure they are not lost in case of problems in the GBIF test environment.

NOTE: If you end up with a dataset suitable for publication to GBIF.org, go to <<publishing_to_gbif>>.
